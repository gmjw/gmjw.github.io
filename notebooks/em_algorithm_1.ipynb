{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Maximisation\n",
    "\n",
    "Suppose we have observed data $x$, unobserved data $z$, and parameters $\\theta$ we are trying to estimate.\n",
    "\n",
    "A sensible estimate of the parameters $\\hat{\\theta}$ would be the parameters that maximise the log likelihood of the observed data $x$.\n",
    "\n",
    "That is, we would like find the parameters that maximise\n",
    "\n",
    "$$\\log P(x |\\ \\theta)$$\n",
    "\n",
    "Note that for any distribution $Q(z)$ on $z$, the unobserved variables, and any particular value of $\\theta$, $\\theta_p$ say, we have\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "& \\log P(x |\\ \\theta_p) \\\\\n",
    "& = \\log \\left( \\sum_z P(x, z\\ |\\ \\theta_p) \\right) \\\\\n",
    "& = \\log \\left( \\sum_z Q(z) \\frac{ P(x, z\\ |\\ \\theta_p)}{Q(z)} \\right) \\\\\n",
    "& \\ge \\sum_z Q(z) \\log \\left( \\frac{ P(x, z\\ |\\ \\theta_p)}{Q(z)} \\right) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last inequality hold via Jensen's inequality, since the penultimate line is the logarithm of an average (where the average is over the distribution of the unobserved variables $Q(z)$). Since log is a concave function, the average of the logarithm'ed quantity is less than the logarithm of the average of the quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the above inequality holds when the distribution $Q(z)$ is the distribution of $z$ given the observed data $x$ and *any* parameters $\\theta$. \n",
    "\n",
    "And in fact, it holds **with equality** in the case when $\\theta = \\theta_p$, since the expression in the last line above (on the right hand side of the inequality) is\n",
    "\n",
    "\\begin{align*}\n",
    "& \\sum_z P(z | x, \\theta_p) \\log \\left( \\frac{ P(x,z|\\ \\theta_p)}{P(z | x, \\theta_p)} \\right) \\\\\n",
    "& = \\sum_z P(z |\\ x, \\theta_p) \\log  P(x|\\ \\theta_p) \\\\\n",
    "& = \\log  P(x|\\ \\theta_p) \\sum_z P(z | x, \\theta_p) \\\\\n",
    "& = \\log  P(x|\\ \\theta_p) \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the inequality above holds for any particular value of our parameters, $\\theta_p$, we can also say that it holds in general for $\\log P(x |\\ \\theta)$ as a function.\n",
    "\n",
    "If we define a function $f(\\theta)$ to be \n",
    "\n",
    "$$\n",
    "f(\\theta) = \\sum_z Q(z) \\log \\left( \\frac{ P(x, z\\ |\\ \\theta)}{Q(z)} \\right)\n",
    "$$\n",
    "\n",
    "then that function is a lower bound for the function\n",
    "\n",
    "$$\n",
    "\\log P(x |\\ \\theta)\n",
    "$$\n",
    "\n",
    "which is the log likelihood we'd like to maximise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we have a current set of parameters, our current best guess, $\\theta^{(t)}$. We wish to form a better guess from these parameters.\n",
    "\n",
    "We can do so as follows: let\n",
    "\n",
    "$$\n",
    "\\theta^{(t + 1)} = argmax_{\\theta}\\ g_t(\\theta)\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "g_t(\\theta) = \\sum_z P(z | x, \\theta^{(t)}) \\log \\left( \\frac{ P(x,z |\\ \\theta)}{P(z | x, \\theta^{(t)})} \\right) \\\\\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a bit complicated.\n",
    "\n",
    "In words: for our next value of theta, we choose the value of $\\theta$ which maximises the expression on the right hand side. When calculating the right hand side, the numerator in the fraction depends on $\\theta$ (i.e. the parameters we are maximising over) and the other terms use only the current value of $\\theta^{(t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then from the definition of the update law, we have \n",
    "\n",
    "$$ g_t(\\theta^{(t+1)}) \\ge g_t(\\theta^{(t)}) $$\n",
    "\n",
    "since by definition $\\theta^{(t+1)}$ is the value that maximises this expression. We could use $\\theta^{(t)}$ in the function $g_t$, but by definition the result that comes out would not be as large as $g_t(\\theta^{(t+1)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that if we put $\\theta^{(t)}$ into our function $g$, then we get $\\log P(x |\\ \\theta^{(t)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that by the argument in the first few cells, we know that $g(\\theta)$ is a lower bound on $P(x\\ |\\ \\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the update rule we have defined allows us to move from a set of parameters $\\theta^{(t)}$ to a new set of parameters $\\theta^{(t+1)}$.\n",
    "\n",
    "Using the inequalities above, we have\n",
    "\n",
    "$$P(x\\ |\\ \\theta^{(t)}) = g_t(\\theta^{(t)}) \\le g_t(\\theta^{(t+1)}) \\le P(x\\ |\\ \\theta^{(t+1)})$$\n",
    "\n",
    "So our new set of parameters $\\theta^{(t+1)}$ give us a better log likelihood than the previous set of parameters $\\theta^{(t)}$. This is great news! We can keep applying the algorithm recursively and we will reach a maximum of the log-likelihood.\n",
    "\n",
    "This might, in unfortunate cases, be a local maximum rather than a global one. It's hard to solve problems with unobserved data. But this is still a great way to iterate towards a sensible solution, and in many cases the technique shown here will allow us to find a global maximum likelihood estimate for $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A slightly simplified update rule\n",
    "\n",
    "Note that in the update rule above we are choosing a value of $\\theta$ that maximises $g_t(\\theta)$. The numerator in the logarithm in the definition of $g_t(\\theta)$ allowed us to use the results higher up and prove that the iterative solution will improve our log-likelihood. But in fact the numerator doesn't affect the value of $\\theta^{(t+1)}$. We can remove it using the rules of logs:\n",
    "\n",
    "\\begin{align}\n",
    "g_t(\\theta) \n",
    "& = \\sum_z P(z | x, \\theta^{(t)}) \\log \\left( \\frac{ P(x,z |\\ \\theta)}{P(z | x, \\theta^{(t)})} \\right) \\\\\n",
    "& = \\sum_z P(z | x, \\theta^{(t)}) \\left( \\log P(x,z |\\ \\theta) - \\log P(z | x, \\theta^{(t)}) \\right) \\\\\n",
    "& = \\sum_z P(z | x, \\theta^{(t)}) \\log P(x,z |\\ \\theta) - \\sum_z P(z | x, \\theta^{(t)}) \\log P(z | x, \\theta^{(t)}) \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the second sum here does not depend on $\\theta$, which is the thing we're varying when looking for the argmax, so we can forget about it and use the update rule\n",
    "\n",
    "$$\n",
    "\\theta^{(t + 1)} = argmax_{\\theta}\\ h_t(\\theta)\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "h_t(\\theta) = \\sum_z P(z | x, \\theta^{(t)}) \\log P(x,z |\\ \\theta)\n",
    "$$\n",
    "\n",
    "This expression is actually just an average, or an *expectation*. It is the expectation of the log likelihood of the full data (including both observed variables $x$ and hidden variables $z$) where the average is taken over the distribution of the hidden variables $z$ given the observed variables and the current best guess of the parameters $\\theta^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can now start to understand our update rule a bit better. We can break into two stages:\n",
    "\n",
    "- Estimate $P(z |\\ x, \\theta^{(t)})$, the distribution of the hidden variables $z$ given the observed variables and the current best guess of the parameters $\\theta^{(t)}$.\n",
    "\n",
    "- Then maximise the function $h_t$ shown above: where $h_t$ is an expected log-likelihood over the distribution of the unobserved variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Here's a very simple example of the above situation, which will hopefully make the EM-algorithm nice and clear.\n",
    "\n",
    "Suppose we have two coins numbered 0 and 1, each with unknown bias, so their probability of throwing a head is $[p_0, p_1]$ respectively.\n",
    "\n",
    "Suppose we have the results of 5 experiments: in each experiment\n",
    "- a coin is chosen at random: coin 0 with probability $\\lambda$, coin 1 with probability $1 - \\lambda$\n",
    "- the chosen coin is tossed 10 times\n",
    "\n",
    "We are given the results of the tosses, *but not which coin was tossed in each experiment*.\n",
    "\n",
    "So our observed data $x$ is the results of all the coin tosses. This can be condensed into the number of heads thrown in each experiment\n",
    "\n",
    "$$ x = [x_0, x_1, x_2, x_3, x_4], 0 \\le x_i \\le 10$$\n",
    "\n",
    "Our unobserved data $z$ is which coin was tossed in which experiment\n",
    "\n",
    "$$ z = [z_0, z_1, z_2, z_3, z_4], z_i \\in [0, 1]$$\n",
    "\n",
    "And our theta is a vector consisting of all the unknown parameters - both coin biases and the probability of choosing coin 0\n",
    "\n",
    "$$\\theta = [p_0, p_1, \\lambda]$$\n",
    "\n",
    "We're going to use our iterative approach, so at each step we'll have a new best guess of the parameters\n",
    "\n",
    "$$\\theta^{(t)} = [p_0^{(t)}, p_1^{(t)}, \\lambda^{(t)}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate $P(z | x, \\theta^{(t)})$. This is the probability of each of our $z_i$, given our current best guess of the parameters.\n",
    "\n",
    "I'm going to stop writing the dependence on $\\theta^{(t)}$ explicitly for a moment, to make the notation a bit easier to read. Instead I'll write \n",
    "\n",
    "$$P_t( \\dots )$$\n",
    "\n",
    "to mean \n",
    "\n",
    "$$P( \\dots |\\ \\theta^{(t)} )$$\n",
    "\n",
    "We have\n",
    "\n",
    "\\begin{align}\n",
    "P(z_i | x, \\theta^{(t)}) \n",
    "& = P_t(z_i | x) \\\\\n",
    "& = P_t(z_i | x_i) \\\\\n",
    "& = \\frac{ P_t(z_i, x_i)}{P_t(x_i)} \\\\\n",
    "\\end{align}\n",
    "\n",
    "by applying Bayes Rule (keeping everything conditional on $\\theta^{(t)}$). Each $z_i$ can either be 0 (if coin 0 was chosen for experiment $i$) or 1 (if coin 1 was chosen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have two coins, the expression above is simple to break down further. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{ P_t(z_i, x_i)}{P_t(x_i)} \n",
    "& = \\frac{ P_t(z_i, x_i)}{\\sum_{j=0,1} P_t(x_i, z_j)} \\\\\n",
    "& = \\frac{ \n",
    "    P_t(x_i | z_i) \n",
    "    P_t( z_i )\n",
    "    }{\n",
    "    \\sum_{j=0,1}\n",
    "    P_t(x_i | z_j) \n",
    "    P_t(z_j)\n",
    "} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to write down what these probabilities actually are. We know that, give our current best guess the parameters $\\theta^{(t)}$\n",
    "\n",
    "For any $i$\n",
    "\\begin{align}\n",
    "P_t(z_i = 0) & = \\lambda^{(t)} \\\\\n",
    "P_t(z_i = 1) & = 1 - \\lambda^{(t)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each $P_t(x_i | z_j)$ term is simply a likelihood from a binomial distribution, assuming the coin thrown, 0 or 1, is known (since $z_j$ is given).\n",
    "\n",
    "If $z_j = 0$, coin 0 was chosen, we use $p_0$ in our binomial pdf. If $z_j = 1$, coin 1 was chosen, we use $p_1$ in our binomial pdf. In either case, we observed $x_i$ heads in experiment $i$, and the total number coin tosses is $n = 10$. So the pdf is\n",
    "\n",
    "$$\n",
    "P_t(x_i | z_j) = \\binom{10}{x_i} \\left(p_{z_j}^{(t)} \\right)^{x_i} \\left( 1 - p_{z_j}^{(t)} \\right)^{10 - x_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this all together, we can write down our pdf for $P(z | x, \\theta^{(t)})$\n",
    "\n",
    "Although the formulas have taken a little while to derive, they're actually very simple to implement. What we end up with is, for each experiment $i$,\n",
    "\n",
    "- $P(z_i = 0 | x_i, \\theta^{(t)})$\n",
    "- $P(z_i = 1 | x_i, \\theta^{(t)})$\n",
    "\n",
    "Let's call these numbers \"weights\", and label them $w_{i,0}^{(t)}$ and $w_{i,1}^{(t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to derive our maximum likelihood estimates of all the parameters, given the function $h_t$ that we will aim to maximise.\n",
    "\n",
    "$$h_t(\\theta) = \\sum_z P(z | x, \\theta^{(t)}) \\log P(x,z |\\ \\theta)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must write down our expression for $\\log P(x, z |\\ \\theta)$.\n",
    "\n",
    "Each experiment is independent, so we have a product of the individual likelihoods, which becomes a sum of the individual likelihoods when we take the logarithm\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(x, z | \\theta) \n",
    "& = \\log \\left( \\prod_i P(x_i, \\ z_i | \\theta) \\right) \\\\\n",
    "& = \\log \\left( \\prod_i P(x_i |\\ z_i, \\theta) P(z_i |\\ \\theta) \\right) \\\\\n",
    "& = \\sum_i \\log \\left( P(x_i |\\ z_i, \\theta) P(z_i |\\ \\theta) \\right) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for each experiment, given $\\theta = (p_0, p_1, \\lambda)$, we know that \n",
    "\n",
    "$$P(z_i = 0) = \\lambda$$\n",
    "$$P(z_i = 1) = 1 - \\lambda$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "P(x_i | z_j) = \\binom{10}{x_i} p_{z_j}^{x_i} \\left( 1 - p_{z_j} \\right)^{10 - x_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the above, we find \n",
    "\n",
    "$$h_t(\\theta) = \\sum_z P(z | x, \\theta^{(t)}) \\log P(x,z |\\ \\theta)$$\n",
    "\n",
    "\\begin{align}\n",
    "& = \\sum_i w_{i,0}^{(t)} \\log \\left( \\binom{10}{x_i} p_{0}^{x_i} \\left( 1 - p_{0} \\right)^{10 - x_i} \\lambda \\right) + \n",
    "\\sum_i w_{i,1}^{(t)} \\log \\left( \\binom{10}{x_i} p_{1}^{x_i} \\left( 1 - p_{1} \\right)^{10 x_i} (1 - \\lambda) \\right) \\\\\n",
    "& = \\sum_i w_{i,0}^{(t)} \\left( \\log \\binom{10}{x_i} + x_i \\log p_{0} + (10 - x_i) \\log \\left( 1 - p_{0} \\right) + \\log \\lambda \\right) \\\\\n",
    "& + \\sum_i w_{i,1}^{(t)} \\left( \\log \\binom{10}{x_i} + x_i \\log p_{1} + (10 - x_i) \\log \\left( 1 - p_{1} \\right) + \\log (1 - \\lambda) \\right) \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the maximum of this expression w.r.t each of the individual elements of $\\theta$, we must differentiate it w.r.t. each variable.\n",
    "\n",
    "We find\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d h_t}{d p_0} =  \\sum_i w_{i,0}^{(t)} \\left( \\frac{x_i}{p_0} + \\frac{-(10 - x_i)}{  1 - p_{0} } \\right) \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equals 0 when \n",
    "\n",
    "\\begin{align}\n",
    "0 & = \\sum_i w_{i,0}^{(t)} \\left( \\frac{x_i}{p_0} + \\frac{-(10 - x_i)}{  1 - p_{0} } \\right) \\\\\n",
    "\\implies \\sum_i w_{i,0}^{(t)} \\frac{x_i}{p_0} & =  \\sum_i w_{i,0}^{(t)} \\frac{10 - x_i}{  1 - p_{0} } \\\\\n",
    "\\implies \\frac{1}{p_0} \\sum_i w_{i,0}^{(t)} x_i & = \\frac{1}{1 - p_0 } \\sum_i w_{i,0}^{(t)} (10 - x_i) \\\\\n",
    "\\implies \\frac{p_0}{1 - p_0 }  & = \\frac{\\sum_i w_{i,0}^{(t)} x_i}{ \\sum_i w_{i,0}^{(t)} (10 - x_i) }\\\\\n",
    "\\implies \\frac{1 - p_0 }{p_0}  & = \\frac{ \\sum_i w_{i,0}^{(t)} (10 - x_i) }{\\sum_i w_{i,0}^{(t)} x_i}\\\\\n",
    "\\implies \\frac{1}{p_0} - 1 & = \\frac{ \\sum_i w_{i,0}^{(t)} (10 - x_i) }{\\sum_i w_{i,0}^{(t)} x_i}\\\\\n",
    "\\implies \\frac{1}{p_0} - 1 & = \\frac{ \\sum_i w_{i,0}^{(t)} 10  }{\\sum_i w_{i,0}^{(t)} x_i} - 1 \\\\\n",
    "\\implies p_0 & = \\frac{\\sum_i w_{i,0}^{(t)} x_i}{ \\sum_i w_{i,0}^{(t)} 10  } \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So we see that the EM-algorithm next step estimate for $p_0$ is \n",
    "\n",
    "- the weighted sum of all the heads observed across all $i$ experiments (when the weights are the probabilities of each coin flip being coin 0) \n",
    "\n",
    "divided by\n",
    "\n",
    "- the weighted sum of all the coin flips across the $i$ experiments (when, once again, the weights are the probabilities of each coin flip being coin 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above expression for $h_t$, by symmetry we can write down the update rule for $p_1$:\n",
    "\n",
    "$$\n",
    "p_1 = \\frac{\\sum_i w_{i,1}^{(t)} x_i}{ \\sum_i w_{i,1}^{(t)} 10  }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the value of $\\lambda$ that maximises $h_t$ is found by differentiating w.r.t. $\\lambda$.\n",
    "\n",
    "$$\\frac{d h_t}{d \\lambda} = \\sum_i w_{i,0}^{(t)} \\frac{1}{ \\lambda } + \\sum_i w_{i,1}^{(t)} \\frac{-1}{ 1 - \\lambda } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And setting the derivative equal to zero, we find\n",
    "\n",
    "\\begin{align}\n",
    "0 & = \\sum_i w_{i,0}^{(t)} \\frac{1}{ \\lambda } + \\sum_i w_{i,1}^{(t)} \\frac{-1}{ 1 - \\lambda } \\\\\n",
    "\\implies \\sum_i w_{i,0}^{(t)} \\frac{1}{ \\lambda }  & =  \\sum_i w_{i,1}^{(t)} \\frac{1}{ 1 - \\lambda } \\\\\n",
    "\\implies \\frac{ 1 - \\lambda }{ \\lambda } & = \\frac{\\sum_i w_{i,1}^{(t)} }{ \\sum_i w_{i,0}^{(t)}} \\\\\n",
    "\\implies  \\frac{ 1 }{ \\lambda } - 1 & = \\frac{\\sum_i w_{i,1}^{(t)} }{ \\sum_i w_{i,0}^{(t)}} \\\\\n",
    "\\implies  \\frac{ 1 }{ \\lambda } & = \\frac{\\sum_i w_{i,1}^{(t)} }{ \\sum_i w_{i,0}^{(t)}} + 1 \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\begin{align}\n",
    "\\implies \\frac{ 1 }{ \\lambda } & = \\frac{\\sum_i w_{i,1}^{(t)} + \\sum_i w_{i,0}^{(t)}}{ \\sum_i w_{i,0}^{(t)}} \\\\\n",
    "\\implies \\lambda & = \\frac{ \\sum_i w_{i,0}^{(t)}}{\\sum_i w_{i,1}^{(t)} + \\sum_i w_{i,0}^{(t)}} \\\\\n",
    "\\implies \\lambda & = \\frac{ \\sum_i w_{i,0}^{(t)}}{ \\sum_i 1} \\\\\n",
    "\\implies \\lambda & =\\frac{ \\sum_i w_{i,0}^{(t)}}{ 5 } \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the best estimate for $\\lambda$ at step $t$ is the sum of the weighted probabilities that coin 0 was used, divided by 5. I hope you'll agree that this makes a lot of sense as an update."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
